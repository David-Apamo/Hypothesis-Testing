---
title: "Hypothesis Testing"
author: "David"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
# Load packages
pacman::p_load(tidyverse, readxl, BSDA, skimr, janitor)
```

```{r}
# Import data
Financials <- read_excel("Financials.xlsx")
```

```{r}
# View the first few observations
head(Financials)
```

```{r}
# View structure of the dataset
glimpse(Financials)
```

The data contains 700 observations of 16 variables. The variables segment, country, product, discount brand, date and month name are of character type, while the rest of the variables are of numeric type (double).

```{r}
# clean the variable names
Financials <- clean_names(Financials)

# have a quick summary of the data
Financials |> skim()
```

Six of the variables in the data are character while 10 are numeric. For the character variables, Segment and Country have 5 unique values each, Product has 6, discount band has 4, date has 16 and month name has 12.

The mean values for units sold, manufacturing price, sales price, gross sales, discounts, sales, cogs and profits are 1608.294, 96.477, 118.429, 182759.426, 13150.355, 169609.072, 145475.211 and 24133.86 respectively.

There are no missing values or white spaces in the data.


# Parametric Tests/Methods

Parametric methods are statistical methods that make specific assumptions about the underlying distribution of the population being studied e.g. the normal distribution. 

* Advantage of Parametric methods:- They have more statistical power than their non-parametric counterparts.

* Disadvantage of Parametric methods:- They strongly rely on data distribution, which may not hold in real-life situations, hence cannot be used if the assumptions are violated.

I'll use 5% as my level of significance throughout this analysis.

## Test for single mean

```{r}
## 1. z-test for single mean

## Test if the true Sales mean = 169609.07
# Ho: mu = 169609.07
# Ha: mu != 169609.07 (two-sided test)
z.test(x = Financials$sales, y = NULL, mu = 169609.07, alternative = "two.sided",
       sigma.x = 236726.3, sigma.y = NULL, conf.level = 0.95)
```

Since the p-value(1) is highly greater than alpha(0.05), I fail to reject Ho at 5% level of significance and conclude that the true Sales mean is equal to 169609.07.

```{r}
## Test if Sales mean is greater than $150,000

# Ho: mu = 150,000
# Ha: mu > 150,000 (right-tailed test)
z.test(x = Financials$sales, y = NULL, mu = 150000, alternative = "greater",
       sigma.x = 236726.3, sigma.y = NULL, conf.level = 0.95)
```

The p-value is less than 0.05. I therefore reject Ho at 5% level of significance and conclude that the true Sales mean is greater than $150,000.

```{r}
## Test if Sales mean is less than $200,000

# Ho: mu = 200,000
# Ha: mu < 200,000 (left-tailed test)
z.test(x = Financials$sales, y = NULL, mu = 200000, alternative = "less",
       sigma.x = 236726.3, sigma.y = NULL, conf.level = 0.95)
```

Since the p-value(0.00034) is much less than alpha(0.05), I reject Ho at 5% level of significance and conclude that the true Sales mean is less than $200,000.

```{r}
## 2. t-test for single mean

## Test if the true Gross Sales mean = 182759.43

# Ho: mu = 182759.43
# Ha: mu != 182759.43 (two-sided test)
t.test(Financials$gross_sales, mu = 182759.43, alternative = "two.sided", 
       conf.level = .95)
```

The p-value is highly greater than 0.05, I fail to reject Ho at 5% level of significance and conclude that true Gross Sales mean is equal to 182759.43.

```{r}
## Test if Gross Sales mean is less than $200,000

# Ho: mu = 200,000
# Ha: mu < 200,000 (left-tailed test)

t.test(Financials$gross_sales, mu = 200000, alternative = "less",
       conf.level = 0.95)
```

The p-value is less than 0.05, I reject Ho at 5% level of significance and conclude that the true Gross Sales mean is less than $200,000.


## Test for difference between two means

```{r}
## 3. z-test for difference between two means (independent samples)

## Test if the means of Sales and Gross sales are different.

# Ho: mu1 = mu2
# Ha: mu1 != mu2 (two-sided test)

z.test(x = Financials$sales, y = Financials$gross_sales, mu = 0,
       alternative = "two.sided", sigma.x = 236726.3,
       sigma.y = 254262.3, conf.level = 0.95)
```

The p-value is highly greater than 0.05, providing enough evidence for zero difference in means. I therefore conclude that there is no significant difference between the means of Sales and Gross Sales.

```{r}
## 4. t-test for difference between two means(independent samples)

## Use independent sample t-test to test if the means of Sales and 
## Gross sales are different. (with an assumption of unequal variances)

# Ho: mu1 = mu2(mu1 - mu2 = 0)
# Ha: mu1 != mu2(mu1 - mu2 != 0) (two-sided test)

t.test(x = Financials$sales, y = Financials$gross_sales, mu = 0,
       alternative = "two.sided", conf.level = 0.95, var.equal = FALSE)
```

Since the p-value(0.3168) is highly greater than alpha(0.05), I fail to reject Ho at 5% level of significance and conclude that the difference in the two means isn't significant.

```{r}
## Again test if the means of Sales and Gross sales are different, with an assumption of equal variances

# Ho: mu1 - mu2 = 0
# Ha: mu1 - mu2 != 0 (two-tailed test)

t.test(x = Financials$sales, y = Financials$gross_sales, mu = 0,
       alternative = "two.sided", conf.level = 0.95, var.equal = TRUE)
```

Since the p-value(0.3168) is highly greater than alpha(0.05), I fail to reject Ho at 5% level of significance and conclude that the difference in the two means is not significant. (assuming that the two populations have equal variances.)

```{r}
## 5. Paired sample t-test (related samples)

## Compare if sales in November 2013 were different from sales in November 2014

# first filter the data for the respective periods
November2013 <- Financials |> filter(month_name == "November" & year == 2013)
November2014 <- Financials |> filter(month_name == "November" & year == 2014)

# formulate the appropriate hypotheses

# Ho: mu1 - mu2 = 0
# Ha: mu1 - mu2 != 0 (two-tailed test)

# carry out the test
t.test(x = November2013$sales, y = November2014$sales, mu = 0,
       paired = TRUE, conf.level = 0.95, var.equal = TRUE)
```

Since the p-value(0.261) is highly greater than 0.05, I fail to reject Ho at 5% level of significance and conclude that the sales made in November 2013 and the sales made in November 2014 were equal. The difference isn't significant.


## Test of significance for Proportions

```{r}
## 6.test for single proportion

## Given that 375 people in a population of 500 test positive for a disease,
# test if more than half of the population tested positive.

# Ho: P = 0.5
# Ha: P > 0.5 (right-tailed test)
prop.test(x = 375, n = 500, p = 0.5, alternative = "greater",
          conf.level = 0.95)
```

Since the p-value is much less than 0.05, I reject Ho at 5% level of significance and conclude that the proportion of the population which tested positive for the disease was more than half.(P > 0.5) From the test results, P = 0.75, which is indeed greater than 0.5.

```{r}
## 7. test for difference between two proportions

# N1 = 500
# N2 = 500
# n1 = 275
# n2 = 250

# Ho: P1 - P2 = 0 (p1 = p2)
# Ha: P1 - P2 != 0 (p1 != p2) [two-tailed test]

prop.test(x = c(275, 250), n = c(500,500), alternative = "two.sided",
          conf.level = 0.95)
```

Since the p-value(0.1286) is greater than 0.05, I fail to reject Ho at 5% level of significance and conclude the the difference in the two proportions is not significant.


## Test for difference between two variances

```{r}
## 8. Variance Test

## Test if there's a difference between the variances of Sales and Gross Sales

# Ho: Sigma1_squared = Sigma2_squared
# Ha: Sigma1_squared != Sigma2_squared (two tailed test)

var.test(Financials$sales, Financials$gross_sales,
         alternative = "two.sided", conf.level = 0.95)
```

The p-value(0.05904) is greater than 0.05, hence I fail to reject Ho at 5% level of significance and conclude that the difference between the two variances is  not significant.


# ONE-WAY ANOVA

```{r}
## 9. Test for difference in means (more than two means)

## test if Sales differ significantly between the countries
## (ANOVA is wide and I covered it in-depth in Design and Analysis of Experiments)

# Ho: Mu1-Mu2...-Mu5 = 0
# H1: Mu1-Mu2...-Mu5 != 0

# fit ANOVA model
mod <- aov(sales ~ country, data = Financials)
# model summary
summary(mod)
```

Since the p-value is highly greater than 0.05, I fail to reject Ho at 5% level of significance and conclude that Sales do not differ significantly between the Countries.


## Non-parametric Tests

Non-parametric tests make very few assumptions about the data distribution.

* Advantage:- Do not rely on data distribution, hence comes in handy if the assumptions of their parametric counterparts are violated.
* Disadvantage: - They usually have less statistical power than their parametric counterparts.

```{r}
## 10. Mann–Whitney U test (Can be used instead of independent sample t-test if the distribution assumptions of the data aren't met.)

# Use Mann–Whitney U test to test whether the probability of obtaining higher
# scores is greater in one population than the other i.e. sales and gross sales

wilcox.test(Financials$sales, Financials$gross_sales,
            alternative = "two.sided", conf.level = 0.95)
```

Since the p-value is greater than 0.05, I fail to reject Ho and conclude that the probability of obtaining higher scores isn't greater in either of the two populations (Sales and Gross Sales).

```{r}
## 11. Mann–Whitney U test for dependent samples (Can be used instead of paired sample t-test if the distribution assumptions of the data aren't met.)

## Compare if sales made in November 2013 were different from sales made in November 2014

wilcox.test(November2013$sales, November2014$sales, 
            paired = TRUE, conf.level = 0.95)
```

The p-value is slightly less than 0.05, hence I reject Ho at 5% level of significance and conclude that true location shift is not equal to 0. In other words, the probability of getting high scores was greater in one population than the other (either in November 2013 or November 2014).

This contradicts the results I obtained in paired sample t-test, but I agree because paired sample t-test is used for small samples (n < 30). My samples for this example are however greater than 30. This can also be one of the situations where they say, "we should not always rely on p-values."

```{r}
## 12. Use Kruskal–Wallis test

## test if Sales differ significantly between the different Segments
## (assuming assumptions for ANOVA aren't met)

# Ho: mu1 = mu2 = ... = mu5
# Ha: At least one of the means is different

kruskal.test(sales ~ segment, data = Financials)
```

The p-value is much less than 0.05, I therefore reject Ho at 5% level of significance and conclude that Sales differ significantly between the Segments.

```{r}
## 13. Chi-square test of Independence

## test if Product and Country are related

# first create a 2 by 2 contingency table of product and country
ContingencyTable <- xtabs(~ product + country, data = Financials)
# print table
ContingencyTable

## formulate the appropriate hypotheses

# Ho: There's no association between Product and Country
# Ha: There's an association between Product and Country

# carry out the test
result <- chisq.test(ContingencyTable)
# print test results
result
```

Since the p-value is highly greater than 0.05, I fail to reject Ho and conclude that Product and Country are not associated.

```{r}
## Case Study: Use of Ascorbic Acid to control cold.

# create a matrix containing the observed frequencies
My_table <- matrix(c(31,109,17,122), nrow = 2, byrow = TRUE)
# name the columns
colnames(My_table) <- c("cold", "no cold")
# name the rows
rownames(My_table) <- c("placebo", "Ascorbic Acid")
# print the table
My_table

## test if there's an association between treatment received and getting cold (i.e. test if the treatment was effective)

# Ho: cold and treatment are independent
# Ha: cold and treatment are associated

# carry out chi-square test of independence
cold_result <- chisq.test(My_table)
# print results
cold_result
```

The p-value is less than 0.05 hence I reject Ho at 5% level of significance and conclude that there is an association between cold and treatment received.

```{r}
## measure the direction of the association

# calculate risk ratio
library(epitools)
riskratio.wald(My_table)
```

The p-value for Ascorbic Acid is less than 0.05, I therefore reject Ho and conclude that patients who took vitamin C (Ascorbic Acid) were less likely to contract cold.

```{r}
# calculate odds ratio
((31*122)/(17*109))
```

The odds of getting cold from placebo was 2.04 times the odds of getting cold from vitamin C. The treatment was therefore effective.


## Finding the Power of a Statistical Test

```{r}
## Find the power of a two sample t-test, given the sample size and the effect size

# load the required package
library(pwr)

# use n1 = 100, n2 = 100
# effect size(d) = 1
# alpha = 0.05
# two-tailed test for two samples

pwr.t.test(n = 100, d = 1, sig.level = 0.05, type = "two.sample", 
           alternative = "two.sided")
```

The statistical power of this test is 0.9999

```{r}
## Find the power of a one sample t-test, given the sample size, effect size and the level of significance

# use n = 50
# effect size(d) = 1.24
# alpha = 0.05
# two-tailed test for one sample

pwr.t.test(n = 50, d = 1.24, sig.level = 0.05, type = "one.sample", 
           alternative = "two.sided")
```

The power of this test is 1.


## Finding the required sample size [given the desired statistical power and effect size]

```{r}
## Find the sample size required for a t-test with effect size d = 0.5,
## alpha = 0.05 and a statistical power of 0.80

d <- 0.5
alpha = 0.05
power = 0.80

sample_size <- pwr.t.test(d = d, sig.level = alpha, power = power,
                          type = "two.sample")
sample_size$n
```

The required sample size is 64.
